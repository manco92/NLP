{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NV8wZ0MTKjv_"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Bot basado en reglas con DNN + Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_9z3H-yKrcK"
   },
   "source": [
    "#### Datos\n",
    "Este ejemplo se inspiró en otro Bot en inglés creado con NLTK, lo tienen como referencia para hacer lo mismo en inglés:\\\n",
    "[LINK](https://towardsdatascience.com/a-simple-chatbot-in-python-with-deep-learning-3e8669997758)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVZakCzAjGN"
   },
   "source": [
    "### 1 - Instalar dependencias\n",
    "Para poder utilizar Spacy en castellano es necesario agregar la librería \"spacy-stanza\" para lematizar palabras en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43420,
     "status": "ok",
     "timestamp": 1656417223713,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "Zd8NLa4gsSmT",
    "outputId": "24710ecc-6285-4235-c08e-bf6c4742a190"
   },
   "outputs": [],
   "source": [
    "# La última versión de spacy-stanza (>1.0) es compatible solo con spacy >=3.0\n",
    "# Nota: spacy 3.0 incorpora al pepiline nlp transformers\n",
    "#!pip install -U spacy==3.1 --quiet\n",
    "#!pip install -U spacy-stanza==1.0.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1656417927489,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "kzao7XO9NJAq"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1656417223714,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "7lWtUZP8ahFk",
    "outputId": "3b37857f-7b66-4b7e-da2a-9c53c0a26a0a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "if os.access('torch_helpers.py', os.F_OK) is False:\n",
    "    if platform.system() == 'Windows':\n",
    "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
    "    else:\n",
    "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463,
     "referenced_widgets": [
      "2e1491f09b1d4d83aa23f9e048f12549",
      "318284ecca2048b3ac6f4fdb62d62d66",
      "65463115440c45d48e3367298a1c3173",
      "17d1a7147abd43c98f9519a914028b3a",
      "752b24a570d14bc198ab4fc44d35d39e",
      "ff2691c1fb714279bd03a28fda9252a6",
      "c20de27ec6b4450dbb1a7df4f208a89c",
      "71bd5ed6192b4c99969afc81d3873292",
      "acea3df585d042c1a8ee0416cda3e283",
      "45efd8b1dc4e476e91c6c1b2d95a685e",
      "52862d780e66465db8dea872b33e912d",
      "28646eec34a843de818b6693e9c6d341",
      "5fef8dc909834f8ea1cb2dc92dad353c",
      "a70c05f499214f229bc2216041af3bc6",
      "d3f53a10da4e479e9cf8569a2cb922ae",
      "2085f017f7bd4edea914d77864d8e857",
      "02e0f9329403449abcec9511e0adf222",
      "17aa0034e7e9403c8e0e23d10242a82e",
      "4291c806ae8348508bd38933f56230af",
      "1935d7a1124e4da0b4fe833eea463e1c",
      "8b9903ed978a4db2899f61f747011173",
      "9f8ac2f26e9648dd9a7befff9b6b1e10"
     ]
    },
    "executionInfo": {
     "elapsed": 103870,
     "status": "ok",
     "timestamp": 1656417327563,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "Z_ExOb8uvjqK",
    "outputId": "95283057-c650-4a3a-d3bc-903569295326"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 22:12:31 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2022-11-02 22:12:31 INFO: Use device: cpu\n",
      "2022-11-02 22:12:31 INFO: Loading: tokenize\n",
      "2022-11-02 22:12:31 INFO: Loading: mwt\n",
      "2022-11-02 22:12:31 INFO: Loading: pos\n",
      "2022-11-02 22:12:32 INFO: Loading: lemma\n",
      "2022-11-02 22:12:32 INFO: Loading: depparse\n",
      "2022-11-02 22:12:32 INFO: Loading: ner\n",
      "2022-11-02 22:12:33 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import spacy_stanza\n",
    "\n",
    "# Vamos a usar SpaCy-Stanza. Stanza es una librería de NLP de Stanford\n",
    "# SpaCy armó un wrapper para los pipelines y modelos de Stanza\n",
    "# https://stanfordnlp.github.io/stanza/\n",
    "\n",
    "# Descargar el diccionario en español y armar el pipeline de NLP con spacy\n",
    "#stanza.download(\"es\")\n",
    "nlp = spacy_stanza.load_pipeline(\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary(corpus):    \n",
    "    l = []\n",
    "    for document in corpus:\n",
    "        doc_split = document.split()\n",
    "        l.append(doc_split)    \n",
    "    flat_list = [item for sublist in l for item in sublist]\n",
    "    vocabulary = list(set(flat_list))\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_inefficient_TFIDF(lista):\n",
    "    voc = vocabulary(lista)\n",
    "    len_voc = len(voc)\n",
    "    len_list = len(lista)\n",
    "    \n",
    "    mat = np.zeros((len_list,len_voc))\n",
    "    \n",
    "    for i, row in enumerate(lista):\n",
    "        sentence = row.split()\n",
    "        for j, col in enumerate(voc):\n",
    "            mat[i,j] = voc[j] in sentence\n",
    "            \n",
    "    mat = np.log10(len_list/np.sum(mat, axis = 0)) * mat\n",
    "    \n",
    "    return pd.DataFrame(mat, columns = voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wF10RjVMBdV"
   },
   "source": [
    "### 2 - Herramientas de preprocesamiento de datos\n",
    "Entre las tareas de procesamiento de texto en español se implementa:\n",
    "- Quitar acentos y caracteres especiales\n",
    "- Quitar números\n",
    "- Quitar símbolos de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1656417327565,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "ZxoD2hEExmuX"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# El preprocesamento en castellano requiere más trabajo\n",
    "\n",
    "# Referencia de regex:\n",
    "# https://docs.python.org/3/library/re.html\n",
    "\n",
    "def preprocess_clean_text(text):    \n",
    "    # sacar tildes de las palabras\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    # quitar caracteres especiales\n",
    "    pattern = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \n",
    "    # quitar números\n",
    "    text = re.sub(pattern, '', text)\n",
    "    # quitar caracteres de puntiación\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1656417327566,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "q-MiMZjh5fu2",
    "outputId": "c147f512-0656-41cc-84cf-a6103987305a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'personas ideas estas cosas y los peces y los muercielagos'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"personas Ideas! estás cosas y los peces y los muercielagos\"\n",
    "\n",
    "# Antes de preprocesar los datos se pasa a mínusculas todo el texto\n",
    "preprocess_clean_text(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1656417328129,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "I9V-S8JbrtNn",
    "outputId": "02665615-b49f-4c2e-ca8f-cba9f4351d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: hola personas ideas estas cosas y los peces y los muercielagos\n",
      "Lematización de cada token:\n",
      "[hola, 'holar']\n",
      "[personas, 'persona']\n",
      "[ideas, 'idea']\n",
      "[estas, 'este']\n",
      "[cosas, 'cosa']\n",
      "[y, 'y']\n",
      "[los, 'el']\n",
      "[peces, 'pez']\n",
      "[y, 'y']\n",
      "[los, 'el']\n",
      "[muercielagos, 'muercielago']\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de como fuciona\n",
    "text = \"hola personas Ideas! estás cosas y los peces y los muercielagos\"\n",
    "\n",
    "# Antes de preprocesar los datos se pasa a mínusculas todo el texto\n",
    "tokes = nlp(preprocess_clean_text(text.lower()))\n",
    "print(\"tokens:\", tokes)\n",
    "print(\"Lematización de cada token:\")\n",
    "for token in tokes:\n",
    "    print([token, token.lemma_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilRbn0KfMm2r"
   },
   "source": [
    "### 3 - Diccionario de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1656417328132,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "NgIGpjymNEH7"
   },
   "outputs": [],
   "source": [
    "# Dataset en formato JSON que representa las posibles preguntas (patterns)\n",
    "# y las posibles respuestas por categoría (tag)\n",
    "dataset = {\"intents\": [\n",
    "             {\"tag\": \"bienvenida\",\n",
    "              \"patterns\": [\"Hola\", \"Cómo estás?\", \"Qué tal?\", \"Buenas tardes\", \"Buenos días\", \"Buenas noches\", \"Todo bien?\", \"Cómo andás?\", \n",
    "                           \"Cómo va?\", \"Cómo va todo?\"],\n",
    "              \"responses\": [\"Hola! Bienvenido a CheemsCafé, en qué puedo ayudarlo?\", \"Hola! Bienvenido a CheemsCafé, cómo puedo ayudarlo?\"]\n",
    "              },\n",
    "             {\"tag\": \"nombre\",\n",
    "              \"patterns\": [\"¿Cúal es tu nombre?\", \"¿Quién sos?\", \"Qué sos?\", \"Cómo te llamás?\"],\n",
    "              \"responses\": [\"Mi nombre es Cheems, amo\", \"Yo soy Cheems, humano\"]\n",
    "             },\n",
    "            {\"tag\": \"contacto\",\n",
    "              \"patterns\": [\"contacto\", \"número de contacto\", \"número de teléfono\", \"número de whatsapp\", \"whatsapp\", \"correo\", \"mail\", \"número de celular\", \n",
    "                           \"horarios de atención\", \"cuándo puedo llamar?\", \"Qué días trabajan?\", \"Qué días atienden?\", \"Dónde puedo comunicarme con ustedes?\",\n",
    "                           \"a qué número puedo conunicar?\", \"Cómo los contacto?\"],\n",
    "              \"responses\": [\"Puede contactarnos al siguiente número, de L a V de 8:00hs a 18:00hs: <número>\"]\n",
    "             },\n",
    "            {\"tag\": \"envios\",\n",
    "              \"patterns\": [\"Realizan envíos?\", \"Cómo me llega el paquete?\", \"Hacen envíos a domicilio?\", \"Tienen delivery?\",\n",
    "                           \"Cuándo me llega?\", \"Cuándo recibo el café?\", \"Cuándo lo entregan?\", \"Qué tiempos de entrega manejan?\",\n",
    "                           \"Envían a la localidad?\", \"Entregan en\", \"Llegan hasta\", \"seguimiento de envíos?\", \"tracking\"],\n",
    "              \"responses\": [\"Realizamos envíos a domicilio. Puede consultar las regiones y tiempos de entrega el siguiente enlace: <link>\"]\n",
    "             },\n",
    "            {\"tag\": \"precios\",\n",
    "              \"patterns\": [\"precio\", \"Me podrás pasar los precios\", \"Cuánto vale?\", \"Cuánto sale?\", \"Cuál es el precio del café?\", \n",
    "                           \"Cuánto cuesta?\", \"Lista de precios\"],\n",
    "              \"responses\": [\"En el siguiente link podrás encontrar los precios de todas nuestras variedades de café: <link>\"]\n",
    "             },\n",
    "            {\"tag\": \"pagos\",\n",
    "              \"patterns\": [\"medios de pago\", \"tarjeta de crédito\", \"tarjetas\", \"cuotas\", \"efectivo\", \"débito\", \"crédito\",\n",
    "                           \"método de pago\", \"forma de pago\", \"promociones\", \"beneficios\", \"qué promociones ofrecen\", \"cómo se paga?\", \"ofrecen algún descuento?\"],\n",
    "              \"responses\": [\"En el siguiente link podrás encontrar las promociones y medios de pago: <link>\"]\n",
    "             },\n",
    "            {\"tag\": \"catálogo\",\n",
    "              \"patterns\": [\"variedad de productos\", \"café\", \"cafés\", \"variedad de cafés\", \"catálogo\", \"stock\", \"stock de cafés\", \"stock de productos\", \"lista de productos\", \n",
    "                           \"venta de cafes\", \"qué cafés venden?\", \"dónde veo cafés para probar?\", \"café descafeinado\",  \"café de especialidad\", \"café saborizado\", \"venden cápsulas\"],\n",
    "              \"responses\": [\"En el siguiente link encontrará las variedades de café que estamos ofreciendo: <link>\"]\n",
    "             },\n",
    "            {\"tag\": \"agradecimientos\",\n",
    "              \"patterns\": [ \"Muchas gracias\", \"Gracias\", \"Agradezco mucho\", \"Le agradezco\", \"Muy amable\"],\n",
    "              \"responses\": [\"Un placer haberlo ayudado, puedo ayudarlo con algo más?\", \"Por nada! Se le ofrece algo más?\"]\n",
    "             },\n",
    "             {\"tag\": \"despedida\",\n",
    "              \"patterns\": [ \"Chau\", \"Hasta luego!\", \"Nada más\", \"Adiós\", \"Nos vemos\"],\n",
    "              \"responses\": [\"Hasta luego! que tenga un excelente día\", \"Muchas gracias por haberse contactado! Hasta la próxima!\"]\n",
    "             },\n",
    "             {\"tag\": \"asistente\",\n",
    "              \"patterns\": [ \"Persona\", \"Operador\", \"Operadora\", \"Gerente\", \"Quiero hablar con una persona\", \"Humano\"],\n",
    "              \"responses\": [\"Enseguida le comunico con uno de nuestros profesionales\"]\n",
    "             },\n",
    "             {\"tag\": \"reclamo\",\n",
    "              \"patterns\": [ \"compré café vencido\", \"recibí una cápsula vencida\", \"el otro día compré café en mal estado\", \n",
    "                            \"el café que encargué tenía muy mal gusto\", \"tuve un problema con el envío\", \"problema\", \"inconveniente\", \"reclamo\",\n",
    "                            \"el café que compré tenía sabor feo\", \"el pedido que hice tenía sabor horrible\"],\n",
    "              \"responses\": [\"Le pido disculpas por el inconveniente. Voy a dejar asentado el reclamo. Se le ofrece algo más?\"]\n",
    "             }\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19PEDmIDfLRu"
   },
   "source": [
    "### 4 - Preprocesamiento y armado del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "executionInfo": {
     "elapsed": 2963,
     "status": "ok",
     "timestamp": 1656417331087,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "b3HP8abHNRk3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leandro\\anaconda3\\lib\\site-packages\\stanza\\models\\common\\beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  prevK = bestScoresId // numWords\n",
      "C:\\Users\\Leandro\\AppData\\Local\\Temp/ipykernel_748/1602494974.py:15: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
      "  tokens = nlp(preprocess_clean_text(pattern.lower()))\n",
      "C:\\Users\\Leandro\\AppData\\Local\\Temp/ipykernel_748/1602494974.py:15: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
      "Words: ['cual', 'es', 'el', 'precio', 'de', 'el', 'cafe']\n",
      "Entities: []\n",
      "  tokens = nlp(preprocess_clean_text(pattern.lower()))\n"
     ]
    }
   ],
   "source": [
    "# Datos que necesitaremos, las palabras o vocabilario\n",
    "words = []\n",
    "classes = []\n",
    "doc_X = []\n",
    "doc_y = []\n",
    "\n",
    "# Por cada intención (intents) debemos tomar los patrones que la caracterízan\n",
    "# a esa intención y transformarla a tokens para lamacenar en doc_X\n",
    "\n",
    "# El tag de cada intención se almacena como doc_Y (la clase a predecir)\n",
    "\n",
    "for intent in dataset[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        # trasformar el patron a tokens\n",
    "        tokens = nlp(preprocess_clean_text(pattern.lower()))\n",
    "        # lematizar los tokens\n",
    "        for token in tokens:            \n",
    "            words.append(token.lemma_)\n",
    "        \n",
    "        doc_X.append(pattern)\n",
    "        doc_y.append(intent[\"tag\"])\n",
    "    \n",
    "    # Agregar el tag a las clases\n",
    "    if intent[\"tag\"] not in classes:\n",
    "        classes.append(intent[\"tag\"])\n",
    "\n",
    "# Elminar duplicados con \"set\" y ordenar el vocubulario y las clases por orden alfabético\n",
    "words = sorted(set(words))\n",
    "classes = sorted(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1656417331088,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "Acy-gcugNbMH",
    "outputId": "bee6f2cd-cf56-475a-e81a-9045c2ac13b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['a', 'adios', 'agradecer', 'alguno', 'amable', 'andar', 'atencion', 'atender', 'beneficio', 'bien', 'buen', 'cafe', 'capsula', 'catalogo', 'celular', 'chau', 'como', 'comprar', 'comunicar', 'con', 'contacto', 'conunicar', 'correo', 'costar', 'credito', 'cual', 'cuando', 'cuanto', 'cuota', 'de', 'debito', 'delivery', 'descafeinado', 'descuento', 'dia', 'domicilio', 'donde', 'efectivo', 'el', 'en', 'encargar', 'entrega', 'entregar', 'enviar', 'envio', 'especialidad', 'estado', 'este', 'feo', 'forma', 'gerente', 'gracias', 'gusto', 'hablar', 'hacer', 'hasta', 'holar', 'horario', 'horrible', 'humano', 'inconveniente', 'ir', 'lista', 'llama', 'llamar', 'llegar', 'localidad', 'luego', 'mail', 'mal', 'manejar', 'mas', 'medio', 'metodo', 'mucho', 'nada', 'noche', 'nombre', 'numerar', 'numero', 'ofrecer', 'operador', 'operadora', 'otro', 'pagar', 'pago', 'paquete', 'para', 'pasar', 'pedido', 'persona', 'poder', 'precio', 'probar', 'problema', 'producto', 'promoción', 'que', 'querer', 'quien', 'realizar', 'recibir', 'recibo', 'reclamo', 'sabor', 'saborizado', 'salir', 'seguimiento', 'ser', 'stock', 'tal', 'tarde', 'tarjeta', 'telefono', 'tener', 'tiempo', 'todo', 'trabajar', 'tracking', 'tu', 'tú', 'uno', 'valer', 'variedad', 'vencido', 'vender', 'venta', 'ver', 'whatsapp', 'yo', 'él']\n",
      "classes: ['agradecimientos', 'asistente', 'bienvenida', 'catálogo', 'contacto', 'despedida', 'envios', 'nombre', 'pagos', 'precios', 'reclamo']\n",
      "doc_X: ['Hola', 'Cómo estás?', 'Qué tal?', 'Buenas tardes', 'Buenos días', 'Buenas noches', 'Todo bien?', 'Cómo andás?', 'Cómo va?', 'Cómo va todo?', '¿Cúal es tu nombre?', '¿Quién sos?', 'Qué sos?', 'Cómo te llamás?', 'contacto', 'número de contacto', 'número de teléfono', 'número de whatsapp', 'whatsapp', 'correo', 'mail', 'número de celular', 'horarios de atención', 'cuándo puedo llamar?', 'Qué días trabajan?', 'Qué días atienden?', 'Dónde puedo comunicarme con ustedes?', 'a qué número puedo conunicar?', 'Cómo los contacto?', 'Realizan envíos?', 'Cómo me llega el paquete?', 'Hacen envíos a domicilio?', 'Tienen delivery?', 'Cuándo me llega?', 'Cuándo recibo el café?', 'Cuándo lo entregan?', 'Qué tiempos de entrega manejan?', 'Envían a la localidad?', 'Entregan en', 'Llegan hasta', 'seguimiento de envíos?', 'tracking', 'precio', 'Me podrás pasar los precios', 'Cuánto vale?', 'Cuánto sale?', 'Cuál es el precio del café?', 'Cuánto cuesta?', 'Lista de precios', 'medios de pago', 'tarjeta de crédito', 'tarjetas', 'cuotas', 'efectivo', 'débito', 'crédito', 'método de pago', 'forma de pago', 'promociones', 'beneficios', 'qué promociones ofrecen', 'cómo se paga?', 'ofrecen algún descuento?', 'variedad de productos', 'café', 'cafés', 'variedad de cafés', 'catálogo', 'stock', 'stock de cafés', 'stock de productos', 'lista de productos', 'venta de cafes', 'qué cafés venden?', 'dónde veo cafés para probar?', 'café descafeinado', 'café de especialidad', 'café saborizado', 'venden cápsulas', 'Muchas gracias', 'Gracias', 'Agradezco mucho', 'Le agradezco', 'Muy amable', 'Chau', 'Hasta luego!', 'Nada más', 'Adiós', 'Nos vemos', 'Persona', 'Operador', 'Operadora', 'Gerente', 'Quiero hablar con una persona', 'Humano', 'compré café vencido', 'recibí una cápsula vencida', 'el otro día compré café en mal estado', 'el café que encargué tenía muy mal gusto', 'tuve un problema con el envío', 'problema', 'inconveniente', 'reclamo', 'el café que compré tenía sabor feo', 'el pedido que hice tenía sabor horrible']\n",
      "doc_y: ['bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'nombre', 'nombre', 'nombre', 'nombre', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'envios', 'envios', 'envios', 'envios', 'envios', 'envios', 'envios', 'envios', 'envios', 'envios', 'envios', 'envios', 'envios', 'precios', 'precios', 'precios', 'precios', 'precios', 'precios', 'precios', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'catálogo', 'agradecimientos', 'agradecimientos', 'agradecimientos', 'agradecimientos', 'agradecimientos', 'despedida', 'despedida', 'despedida', 'despedida', 'despedida', 'asistente', 'asistente', 'asistente', 'asistente', 'asistente', 'asistente', 'reclamo', 'reclamo', 'reclamo', 'reclamo', 'reclamo', 'reclamo', 'reclamo', 'reclamo', 'reclamo', 'reclamo']\n"
     ]
    }
   ],
   "source": [
    "print(\"words:\", words)\n",
    "print(\"classes:\", classes)\n",
    "print(\"doc_X:\", doc_X)\n",
    "print(\"doc_y:\", doc_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1656417331089,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "YI0L2U7IQcvy",
    "outputId": "198caa1a-fa6a-48fb-ebe6-97c7c1b51b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 131\n"
     ]
    }
   ],
   "source": [
    "# Tamaño del vocabulario\n",
    "print(\"Vocabulario:\", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1656417331090,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "hqBeGKRk_q4r",
    "outputId": "80d36ae1-35a3-4a17-91c9-81a31baa079b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags: 11\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de tags\n",
    "print(\"Tags:\", len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  3., 16.,  2.,\n",
       "        1.,  1.,  1.,  8.,  3.,  1.,  3.,  3.,  1.,  1.,  1.,  2.,  2.,\n",
       "        4.,  3.,  1., 20.,  1.,  1.,  1.,  1.,  4.,  1.,  2.,  1., 12.,\n",
       "        2.,  1.,  1.,  2.,  1.,  4.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,\n",
       "        1.,  1.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  1.,  1.,\n",
       "        3.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  4.,  1.,  1.,  1.,\n",
       "        1.,  4.,  2.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,  1.,  2.,\n",
       "        4.,  4.,  1.,  2.,  3.,  2., 11.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        2.,  1.,  1.,  1.,  4.,  3.,  1.,  1.,  2.,  1.,  5.,  1.,  2.,\n",
       "        1.,  1.,  1.,  2.,  3.,  1.,  2.,  2.,  2.,  1.,  2.,  2.,  5.,\n",
       "        3.])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mat, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3097,
     "status": "ok",
     "timestamp": 1656417334176,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "vpbJ0guPN2Uq",
    "outputId": "5865dc76-beb9-41dc-b8bd-e8c2a8af4563"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leandro\\AppData\\Local\\Temp/ipykernel_748/4101623336.py:13: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
      "  tokens = nlp(preprocess_clean_text(doc.lower()))\n",
      "C:\\Users\\Leandro\\AppData\\Local\\Temp/ipykernel_748/4101623336.py:13: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
      "Words: ['cual', 'es', 'el', 'precio', 'de', 'el', 'cafe']\n",
      "Entities: []\n",
      "  tokens = nlp(preprocess_clean_text(doc.lower()))\n"
     ]
    }
   ],
   "source": [
    "# Transformar doc_X en bag of words por oneHotEncoding\n",
    "# Transformar doc_Y en un vector de clases multicategórico con oneHotEncoding\n",
    "\n",
    "training = []\n",
    "out_empty = [0] * len(classes)\n",
    "\n",
    "mat = np.zeros((len(doc_X), len(words)))\n",
    "\n",
    "for idx, doc in enumerate(doc_X):\n",
    "               \n",
    "    # Transformar la pregunta (input) en tokens y lematizar\n",
    "    text = []\n",
    "    tokens = nlp(preprocess_clean_text(doc.lower()))\n",
    "    for token in tokens:\n",
    "        text.append(token.lemma_)            \n",
    "    \n",
    "    # Transformar los tokens en \"Bag of words\" (arrays de 1 y 0)\n",
    "    #bow = []\n",
    "    for col, word in enumerate(words):\n",
    "        #bow.append(1) if word in text else bow.append(0)\n",
    "        mat[idx, col] = text.count(word)\n",
    "        \n",
    "transf_mat = np.log10(len(doc_X)/np.sum(mat, axis = 0)) * mat\n",
    "\n",
    "for idx, doc in enumerate(doc_X):\n",
    "    \n",
    "    # Crear el array de salida (class output) correspondiente\n",
    "    output_row = list(out_empty)\n",
    "    output_row[classes.index(doc_y[idx])] = 1\n",
    "    \n",
    "    tf_idf = list(transf_mat[idx].reshape(1, len(words)))\n",
    "    \n",
    "    #print(\"X:\", tf_idf[0], \"y:\", output_row)\n",
    "    training.append([tf_idf[0], output_row])    \n",
    "\n",
    "# Mezclar los datos\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype = object)\n",
    "# Dividir en datos de entrada y salida\n",
    "train_X = np.array(list(training[:, 0]))\n",
    "train_y = np.array(list(training[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1656417334177,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "GQaGSWBtauBn",
    "outputId": "cb51b63a-4b96-4cf7-ef57-b8440084913b"
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        # Convertir los arrays de numpy a tensores. \n",
    "        # pytorch espera en general entradas 32bits\n",
    "        self.x = torch.from_numpy(x.astype(np.float32))\n",
    "        # las loss function esperan la salida float\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "        self.len = self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "data_set = Data(train_X, train_y)\n",
    "\n",
    "input_dim = data_set.x.shape[1]\n",
    "print(\"Input dim\", input_dim)\n",
    "\n",
    "output_dim = data_set.y.shape[1]\n",
    "print(\"Output dim\", output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1656417892198,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "cGw7uV47LuJx"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(data_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_Hr8QaDfRf3"
   },
   "source": [
    "### 5 - Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1656417894757,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "7FNoKNeSbVmY",
    "outputId": "40139e9e-1f2d-47f9-f4aa-905dc1e055a8"
   },
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=input_dim, out_features=128) # fully connected layer\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=64) # fully connected layer\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=output_dim) # fully connected layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1) # normalize in dim 1\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.softmax(self.fc3(out))\n",
    "        return out\n",
    "\n",
    "# Crear el modelo basado en la arquitectura definida\n",
    "model1 = Model1(input_dim=input_dim, output_dim=output_dim)\n",
    "# Crear el optimizador la una función de error\n",
    "model1_optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "model1_criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
    "\n",
    "#torchsummary.summary(model1, input_size=(1, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1656417873035,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "-Ap_Ts8Ga39y"
   },
   "outputs": [],
   "source": [
    "from torch_helpers import categorical_acc\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, epochs = 100):\n",
    "    # Defino listas para realizar graficas de los resultados\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "\n",
    "    ## Defino mi loop de entrenamiento\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_accuracy = 0.0\n",
    "\n",
    "        for train_data, train_target in train_loader:\n",
    "\n",
    "            # Seteo los gradientes en cero ya que, por defecto, PyTorch\n",
    "            # los va acumulando\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(train_data)\n",
    "\n",
    "            # Computo el error de la salida comparando contra las etiquetas\n",
    "            loss = criterion(output, train_target)\n",
    "\n",
    "            # Almaceno el error del batch para luego tener el error promedio de la epoca\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "            # Computo el nuevo set de gradientes a lo largo de toda la red\n",
    "            loss.backward()\n",
    "\n",
    "            # Realizo el paso de optimizacion actualizando los parametros de toda la red\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculo el accuracy del batch\n",
    "            accuracy = categorical_acc(output, train_target)\n",
    "            # Almaceno el accuracy del batch para luego tener el accuracy promedio de la epoca\n",
    "            epoch_train_accuracy += accuracy.item()\n",
    "\n",
    "        # Calculo la media de error y accuracy para la epoca de entrenamiento.\n",
    "        # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n",
    "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)        \n",
    "        train_accuracy.append(epoch_train_accuracy)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Train accuracy {epoch_train_accuracy:.3f}\")\n",
    "\n",
    "    history = {\n",
    "        \"loss\": train_loss,\n",
    "        \"accuracy\": train_accuracy,\n",
    "    }\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 961,
     "status": "ok",
     "timestamp": 1656417901433,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "r6hi4EcdOghm",
    "outputId": "03a56f27-fa93-4990-fabe-2113da72cdf5"
   },
   "outputs": [],
   "source": [
    "history1 = train(model1,\n",
    "                train_loader,\n",
    "                model1_optimizer,\n",
    "                model1_criterion,\n",
    "                epochs=200\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 1034,
     "status": "ok",
     "timestamp": 1656417942693,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "Pb1GZDjGRP6Q",
    "outputId": "c04d5435-c5e6-48ac-9f13-9de67e493a7c"
   },
   "outputs": [],
   "source": [
    "epoch_count = range(1, len(history1['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history1['accuracy'], label='train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnD1WvhBfVYR"
   },
   "source": [
    "### 6 - Testing y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656418138142,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "kqBdSGt8Orkm"
   },
   "outputs": [],
   "source": [
    "def text_to_tokens(text): \n",
    "    lemma_tokens = []\n",
    "    tokens = nlp(preprocess_clean_text(text.lower()))\n",
    "    for token in tokens:\n",
    "        lemma_tokens.append(token.lemma_)\n",
    "    #print(lemma_tokens)\n",
    "    return lemma_tokens\n",
    "\n",
    "def bag_of_words(text, vocab): \n",
    "    tokens = text_to_tokens(text)\n",
    "    bow = [0] * len(vocab)\n",
    "    for w in tokens: \n",
    "        for idx, word in enumerate(vocab):\n",
    "            if word == w: \n",
    "                bow[idx] = 1\n",
    "    #print(bow)\n",
    "    return np.array(bow)\n",
    "\n",
    "def tf_idf(text, vocab, mat): \n",
    "    tokens = text_to_tokens(text)\n",
    "    bow = [0] * len(vocab)\n",
    "    for idx, word in enumerate(vocab):\n",
    "        bow[idx] = tokens.count(word)\n",
    "        \n",
    "    tf_idf = np.log10(len(mat)/np.sum(mat, axis = 0)) * np.array(bow)\n",
    "    return tf_idf\n",
    "\n",
    "def pred_class(text, vocab, labels, mat): \n",
    "    bow = tf_idf(text, vocab, mat)\n",
    "    words_recognized = sum(bow)\n",
    "\n",
    "    return_list = []\n",
    "    if words_recognized > 0:\n",
    "        x = torch.from_numpy(np.array([bow]).astype(np.float32))\n",
    "        result = model1(x)[0].detach().numpy()\n",
    "        thresh = 0.2\n",
    "        y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
    "        y_pred.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "        for r in y_pred:\n",
    "            return_list.append(labels[r[0]])\n",
    "            #print(labels[r[0]], r[1])\n",
    "\n",
    "    return return_list\n",
    "\n",
    "def get_response(intents_list, intents_json):\n",
    "    tag = intents_list[0]\n",
    "    list_of_intents = intents_json[\"intents\"]\n",
    "    for i in list_of_intents: \n",
    "        if i[\"tag\"] == tag:\n",
    "            result = \"BOT: \" + random.choice(i[\"responses\"])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1656418140912,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "CivDeypZNF2o",
    "outputId": "3885edbb-f1aa-44ca-e716-e9ac777f43d2"
   },
   "outputs": [],
   "source": [
    "message = \"Hola buenos dias\"\n",
    "intents = pred_class(message, words, classes, transf_mat)\n",
    "if len(intents) > 0:\n",
    "    result = get_response(intents, dataset)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xp1vXQwdOvl7"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    message = input(\"\")\n",
    "    intents = pred_class(message, words, classes, transf_mat)\n",
    "    if len(intents) > 0:\n",
    "        result = get_response(intents, dataset)\n",
    "        print(result)\n",
    "    else:\n",
    "        print(\"Perdón, no comprendo la pregunta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.85, 1],[0.74, 2]])\n",
    "A.T @ A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayatkwp4fYQx"
   },
   "source": [
    "### 7 - Conclusiones\n",
    "El bot tal cual está definido es capaz de responder a bastantes tipos de preguntas con gran precisión. Algunas técnicas que podrían ensayarse para evaluar como impactan en el sistema son:\n",
    "- Filtrar los stop words\n",
    "- Utilizar multi label classification:\\\n",
    "https://machinelearningmastery.com/multi-label-classification-with-deep-learning/\n",
    "- Utilizar TF-IDF en vez de bag of words"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2b - bot_dnn_spacy_esp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02e0f9329403449abcec9511e0adf222": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17aa0034e7e9403c8e0e23d10242a82e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17d1a7147abd43c98f9519a914028b3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45efd8b1dc4e476e91c6c1b2d95a685e",
      "placeholder": "​",
      "style": "IPY_MODEL_52862d780e66465db8dea872b33e912d",
      "value": " 140k/? [00:00&lt;00:00, 3.10MB/s]"
     }
    },
    "1935d7a1124e4da0b4fe833eea463e1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2085f017f7bd4edea914d77864d8e857": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28646eec34a843de818b6693e9c6d341": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5fef8dc909834f8ea1cb2dc92dad353c",
       "IPY_MODEL_a70c05f499214f229bc2216041af3bc6",
       "IPY_MODEL_d3f53a10da4e479e9cf8569a2cb922ae"
      ],
      "layout": "IPY_MODEL_2085f017f7bd4edea914d77864d8e857"
     }
    },
    "2e1491f09b1d4d83aa23f9e048f12549": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_318284ecca2048b3ac6f4fdb62d62d66",
       "IPY_MODEL_65463115440c45d48e3367298a1c3173",
       "IPY_MODEL_17d1a7147abd43c98f9519a914028b3a"
      ],
      "layout": "IPY_MODEL_752b24a570d14bc198ab4fc44d35d39e"
     }
    },
    "318284ecca2048b3ac6f4fdb62d62d66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff2691c1fb714279bd03a28fda9252a6",
      "placeholder": "​",
      "style": "IPY_MODEL_c20de27ec6b4450dbb1a7df4f208a89c",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: "
     }
    },
    "4291c806ae8348508bd38933f56230af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45efd8b1dc4e476e91c6c1b2d95a685e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52862d780e66465db8dea872b33e912d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5fef8dc909834f8ea1cb2dc92dad353c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02e0f9329403449abcec9511e0adf222",
      "placeholder": "​",
      "style": "IPY_MODEL_17aa0034e7e9403c8e0e23d10242a82e",
      "value": "Downloading http://nlp.stanford.edu/software/stanza/1.2.2/es/default.zip: 100%"
     }
    },
    "65463115440c45d48e3367298a1c3173": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71bd5ed6192b4c99969afc81d3873292",
      "max": 24144,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_acea3df585d042c1a8ee0416cda3e283",
      "value": 24144
     }
    },
    "71bd5ed6192b4c99969afc81d3873292": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "752b24a570d14bc198ab4fc44d35d39e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b9903ed978a4db2899f61f747011173": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f8ac2f26e9648dd9a7befff9b6b1e10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a70c05f499214f229bc2216041af3bc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4291c806ae8348508bd38933f56230af",
      "max": 565553347,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1935d7a1124e4da0b4fe833eea463e1c",
      "value": 565553347
     }
    },
    "acea3df585d042c1a8ee0416cda3e283": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c20de27ec6b4450dbb1a7df4f208a89c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3f53a10da4e479e9cf8569a2cb922ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b9903ed978a4db2899f61f747011173",
      "placeholder": "​",
      "style": "IPY_MODEL_9f8ac2f26e9648dd9a7befff9b6b1e10",
      "value": " 566M/566M [01:44&lt;00:00, 5.27MB/s]"
     }
    },
    "ff2691c1fb714279bd03a28fda9252a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
